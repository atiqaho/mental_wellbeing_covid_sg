{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import datetime as datetime \n",
    "import pickle \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll = pd.read_csv('twitter_noninfluencers_withemotioncat.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mw_dataset_no_dup_no_troll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Date</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>valence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_status_count</th>\n",
       "      <th>user_follower</th>\n",
       "      <th>user_friend</th>\n",
       "      <th>influencer_score</th>\n",
       "      <th>info_status</th>\n",
       "      <th>info_status_binary</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>intensity_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580179e+09</td>\n",
       "      <td>First person with the Wuhan virus being treate...</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.150286e+18</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.701641</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580179e+09</td>\n",
       "      <td>We have this chat group for everyone in SG off...</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.428</td>\n",
       "      <td>2.055352e+08</td>\n",
       "      <td>35226.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580180e+09</td>\n",
       "      <td>chrisvtaylor pakhead RichardBarrow Safe harbor...</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.390</td>\n",
       "      <td>1.170536e+18</td>\n",
       "      <td>489.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580180e+09</td>\n",
       "      <td>After the 5th Wuhan imported case confirmed Si...</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.501</td>\n",
       "      <td>2.913063e+07</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580181e+09</td>\n",
       "      <td>Coronavirus news France to airlift citizens ou...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.323</td>\n",
       "      <td>2.271343e+08</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    ID keywords      Date  tweet_timestamp  \\\n",
       "0           7             7   8.0    wuhan  01/28/20     1.580179e+09   \n",
       "1           8             8   9.0    wuhan  01/28/20     1.580179e+09   \n",
       "2           9             9  10.0    wuhan  01/28/20     1.580180e+09   \n",
       "3          10            10  11.0    wuhan  01/28/20     1.580180e+09   \n",
       "4          13            13  14.0    wuhan  01/28/20     1.580181e+09   \n",
       "\n",
       "                                               Tweet  anger   fear  sadness  \\\n",
       "0  First person with the Wuhan virus being treate...  0.483  0.530    0.450   \n",
       "1  We have this chat group for everyone in SG off...  0.428  0.523    0.470   \n",
       "2  chrisvtaylor pakhead RichardBarrow Safe harbor...  0.505  0.594    0.474   \n",
       "3  After the 5th Wuhan imported case confirmed Si...  0.414  0.499    0.471   \n",
       "4  Coronavirus news France to airlift citizens ou...  0.534  0.680    0.549   \n",
       "\n",
       "     joy  valence       user_id  user_status_count  user_follower  \\\n",
       "0  0.251    0.408  1.150286e+18              337.0         1411.0   \n",
       "1  0.280    0.428  2.055352e+08            35226.0          336.0   \n",
       "2  0.231    0.390  1.170536e+18              489.0           13.0   \n",
       "3  0.332    0.501  2.913063e+07            44406.0          693.0   \n",
       "4  0.182    0.323  2.271343e+08              117.0            1.0   \n",
       "\n",
       "   user_friend  influencer_score   info_status  info_status_binary emotion  \\\n",
       "0       2011.0          0.701641  info-seeking                   1    fear   \n",
       "1        473.0          0.710359  info-seeking                   1    fear   \n",
       "2        221.0          0.058824  info-seeking                   1    fear   \n",
       "3       1285.0          0.539300  info-seeking                   1    fear   \n",
       "4        147.0          0.006803  info-seeking                   1    fear   \n",
       "\n",
       "  sentiment intensity_level  \n",
       "0  negative        moderate  \n",
       "1  negative        moderate  \n",
       "2  negative        moderate  \n",
       "3   neutral        moderate  \n",
       "4  negative            high  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'ID', 'keywords', 'Date',\n",
       "       'tweet_timestamp', 'Tweet', 'anger', 'fear', 'sadness', 'joy',\n",
       "       'valence', 'user_id', 'user_status_count', 'user_follower',\n",
       "       'user_friend', 'influencer_score', 'info_status', 'info_status_binary',\n",
       "       'emotion', 'sentiment', 'intensity_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll['Tweet'] = mw_dataset_no_dup_no_troll['Tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "def clean_text_1(headline):\n",
    "    headline = headline.lower()\n",
    "    headline = re.sub('\\[.,*?\\]','',headline)\n",
    "    headline = re.sub('[0-9]','',headline)\n",
    "    headline = re.sub('[%s]' % re.escape(string.punctuation), '', headline)\n",
    "    headline = re.sub('[‘’“”…–]', '', headline)\n",
    "    headline = re.sub('\\w*\\d\\n\\w*', '', headline)\n",
    "    return headline\n",
    "\n",
    "#def replace_contractions(text):\n",
    "    #\"\"\"Replace contractions in string of text\"\"\"\n",
    "    #return contractions.fix(text)\n",
    "\n",
    "def remove_mentions(sample):\n",
    "    \"\"\"Remove mentions from a sample string\"\"\"\n",
    "    return re.sub(r\"@\\S+\", \"\", str(sample))\n",
    "    \n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", str(sample))\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', str(word))\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def normalize(words):\n",
    "    #words = replace_numbers(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    return words\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample = remove_URL(sample)\n",
    "    sample= remove_mentions(sample)\n",
    "    #sample = replace_contractions(sample)\n",
    "    # Tokenize\n",
    "    words = nltk.word_tokenize(sample)\n",
    "\n",
    "    # Normalize\n",
    "    return normalize(words)\n",
    "\n",
    "\n",
    "round_1 = lambda x: preprocess(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll['processed_content'] = mw_dataset_no_dup_no_troll['Tweet'].apply(round_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll['processed_content']=mw_dataset_no_dup_no_troll['processed_content'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    first person with the wuhan virus being treate...\n",
       "1    we have this chat group for everyone in sg off...\n",
       "2    chrisvtaylor pakhead richardbarrow safe harbor...\n",
       "3    after the 5th wuhan imported case confirmed si...\n",
       "4    coronavirus news france to airlift citizens ou...\n",
       "Name: processed_content, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll['processed_content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Date</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>valence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_status_count</th>\n",
       "      <th>user_follower</th>\n",
       "      <th>user_friend</th>\n",
       "      <th>influencer_score</th>\n",
       "      <th>info_status</th>\n",
       "      <th>info_status_binary</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>intensity_level</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580179e+09</td>\n",
       "      <td>First person with the Wuhan virus being treate...</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.150286e+18</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.701641</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "      <td>first person with the wuhan virus being treate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580179e+09</td>\n",
       "      <td>We have this chat group for everyone in SG off...</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.428</td>\n",
       "      <td>2.055352e+08</td>\n",
       "      <td>35226.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "      <td>we have this chat group for everyone in sg off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580180e+09</td>\n",
       "      <td>chrisvtaylor pakhead RichardBarrow Safe harbor...</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.390</td>\n",
       "      <td>1.170536e+18</td>\n",
       "      <td>489.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "      <td>chrisvtaylor pakhead richardbarrow safe harbor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580180e+09</td>\n",
       "      <td>After the 5th Wuhan imported case confirmed Si...</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.501</td>\n",
       "      <td>2.913063e+07</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>moderate</td>\n",
       "      <td>after the 5th wuhan imported case confirmed si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580181e+09</td>\n",
       "      <td>Coronavirus news France to airlift citizens ou...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.323</td>\n",
       "      <td>2.271343e+08</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>high</td>\n",
       "      <td>coronavirus news france to airlift citizens ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    ID keywords      Date  tweet_timestamp  \\\n",
       "0           7             7   8.0    wuhan  01/28/20     1.580179e+09   \n",
       "1           8             8   9.0    wuhan  01/28/20     1.580179e+09   \n",
       "2           9             9  10.0    wuhan  01/28/20     1.580180e+09   \n",
       "3          10            10  11.0    wuhan  01/28/20     1.580180e+09   \n",
       "4          13            13  14.0    wuhan  01/28/20     1.580181e+09   \n",
       "\n",
       "                                               Tweet  anger   fear  sadness  \\\n",
       "0  First person with the Wuhan virus being treate...  0.483  0.530    0.450   \n",
       "1  We have this chat group for everyone in SG off...  0.428  0.523    0.470   \n",
       "2  chrisvtaylor pakhead RichardBarrow Safe harbor...  0.505  0.594    0.474   \n",
       "3  After the 5th Wuhan imported case confirmed Si...  0.414  0.499    0.471   \n",
       "4  Coronavirus news France to airlift citizens ou...  0.534  0.680    0.549   \n",
       "\n",
       "     joy  valence       user_id  user_status_count  user_follower  \\\n",
       "0  0.251    0.408  1.150286e+18              337.0         1411.0   \n",
       "1  0.280    0.428  2.055352e+08            35226.0          336.0   \n",
       "2  0.231    0.390  1.170536e+18              489.0           13.0   \n",
       "3  0.332    0.501  2.913063e+07            44406.0          693.0   \n",
       "4  0.182    0.323  2.271343e+08              117.0            1.0   \n",
       "\n",
       "   user_friend  influencer_score   info_status  info_status_binary emotion  \\\n",
       "0       2011.0          0.701641  info-seeking                   1    fear   \n",
       "1        473.0          0.710359  info-seeking                   1    fear   \n",
       "2        221.0          0.058824  info-seeking                   1    fear   \n",
       "3       1285.0          0.539300  info-seeking                   1    fear   \n",
       "4        147.0          0.006803  info-seeking                   1    fear   \n",
       "\n",
       "  sentiment intensity_level                                  processed_content  \n",
       "0  negative        moderate  first person with the wuhan virus being treate...  \n",
       "1  negative        moderate  we have this chat group for everyone in sg off...  \n",
       "2  negative        moderate  chrisvtaylor pakhead richardbarrow safe harbor...  \n",
       "3   neutral        moderate  after the 5th wuhan imported case confirmed si...  \n",
       "4  negative            high  coronavirus news france to airlift citizens ou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mw_dataset_no_dup_no_troll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#fb_clean['processed_content'] = fb_clean['processed_content'].astype('str').apply(lambda x: filter(None,x.split(\" \")))\n",
    "#fb_clean['processed_content'] = fb_clean['processed_content'].apply(lambda x : [wordnet_lemmatizer.lemmatize(y) for y in x])\n",
    "#fb_clean['processed_content']=fb_clean['processed_content'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "mw_dataset_no_dup_no_troll['lemmatized_content'] = mw_dataset_no_dup_no_troll['processed_content'].astype('str').apply(lambda x: filter(None,x.split(\" \")))\n",
    "#df['processed_content'] = df['processed_content'].apply(lambda x : [wordnet_lemmatizer.lemmatize(y) for y in x])\n",
    "mw_dataset_no_dup_no_troll['lemmatized_content'] = mw_dataset_no_dup_no_troll['lemmatized_content'].apply(lambda x : [stemmer.stem(y) for y in x])\n",
    "mw_dataset_no_dup_no_troll['lemmatized_content'] = mw_dataset_no_dup_no_troll['lemmatized_content'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Date</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>valence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_status_count</th>\n",
       "      <th>user_follower</th>\n",
       "      <th>user_friend</th>\n",
       "      <th>influencer_score</th>\n",
       "      <th>info_status</th>\n",
       "      <th>info_status_binary</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>intensity_level</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580179e+09</td>\n",
       "      <td>First person with the Wuhan virus being treate...</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.150286e+18</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.701641</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "      <td>first person with the wuhan virus being treate...</td>\n",
       "      <td>first person with the wuhan virus be treat by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580179e+09</td>\n",
       "      <td>We have this chat group for everyone in SG off...</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.428</td>\n",
       "      <td>2.055352e+08</td>\n",
       "      <td>35226.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "      <td>we have this chat group for everyone in sg off...</td>\n",
       "      <td>we have this chat group for everyon in sg offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580180e+09</td>\n",
       "      <td>chrisvtaylor pakhead RichardBarrow Safe harbor...</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.390</td>\n",
       "      <td>1.170536e+18</td>\n",
       "      <td>489.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>moderate</td>\n",
       "      <td>chrisvtaylor pakhead richardbarrow safe harbor...</td>\n",
       "      <td>chrisvtaylor pakhead richardbarrow safe harbor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580180e+09</td>\n",
       "      <td>After the 5th Wuhan imported case confirmed Si...</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.501</td>\n",
       "      <td>2.913063e+07</td>\n",
       "      <td>44406.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>moderate</td>\n",
       "      <td>after the 5th wuhan imported case confirmed si...</td>\n",
       "      <td>after the 5th wuhan import case confirm singap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>01/28/20</td>\n",
       "      <td>1.580181e+09</td>\n",
       "      <td>Coronavirus news France to airlift citizens ou...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.323</td>\n",
       "      <td>2.271343e+08</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>info-seeking</td>\n",
       "      <td>1</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>high</td>\n",
       "      <td>coronavirus news france to airlift citizens ou...</td>\n",
       "      <td>coronavirus news franc to airlift citizen out ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    ID keywords      Date  tweet_timestamp  \\\n",
       "0           7             7   8.0    wuhan  01/28/20     1.580179e+09   \n",
       "1           8             8   9.0    wuhan  01/28/20     1.580179e+09   \n",
       "2           9             9  10.0    wuhan  01/28/20     1.580180e+09   \n",
       "3          10            10  11.0    wuhan  01/28/20     1.580180e+09   \n",
       "4          13            13  14.0    wuhan  01/28/20     1.580181e+09   \n",
       "\n",
       "                                               Tweet  anger   fear  sadness  \\\n",
       "0  First person with the Wuhan virus being treate...  0.483  0.530    0.450   \n",
       "1  We have this chat group for everyone in SG off...  0.428  0.523    0.470   \n",
       "2  chrisvtaylor pakhead RichardBarrow Safe harbor...  0.505  0.594    0.474   \n",
       "3  After the 5th Wuhan imported case confirmed Si...  0.414  0.499    0.471   \n",
       "4  Coronavirus news France to airlift citizens ou...  0.534  0.680    0.549   \n",
       "\n",
       "     joy  valence       user_id  user_status_count  user_follower  \\\n",
       "0  0.251    0.408  1.150286e+18              337.0         1411.0   \n",
       "1  0.280    0.428  2.055352e+08            35226.0          336.0   \n",
       "2  0.231    0.390  1.170536e+18              489.0           13.0   \n",
       "3  0.332    0.501  2.913063e+07            44406.0          693.0   \n",
       "4  0.182    0.323  2.271343e+08              117.0            1.0   \n",
       "\n",
       "   user_friend  influencer_score   info_status  info_status_binary emotion  \\\n",
       "0       2011.0          0.701641  info-seeking                   1    fear   \n",
       "1        473.0          0.710359  info-seeking                   1    fear   \n",
       "2        221.0          0.058824  info-seeking                   1    fear   \n",
       "3       1285.0          0.539300  info-seeking                   1    fear   \n",
       "4        147.0          0.006803  info-seeking                   1    fear   \n",
       "\n",
       "  sentiment intensity_level  \\\n",
       "0  negative        moderate   \n",
       "1  negative        moderate   \n",
       "2  negative        moderate   \n",
       "3   neutral        moderate   \n",
       "4  negative            high   \n",
       "\n",
       "                                   processed_content  \\\n",
       "0  first person with the wuhan virus being treate...   \n",
       "1  we have this chat group for everyone in sg off...   \n",
       "2  chrisvtaylor pakhead richardbarrow safe harbor...   \n",
       "3  after the 5th wuhan imported case confirmed si...   \n",
       "4  coronavirus news france to airlift citizens ou...   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0  first person with the wuhan virus be treat by ...  \n",
       "1  we have this chat group for everyon in sg offi...  \n",
       "2  chrisvtaylor pakhead richardbarrow safe harbor...  \n",
       "3  after the 5th wuhan import case confirm singap...  \n",
       "4  coronavirus news franc to airlift citizen out ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll.to_csv('twitter_full_noninfluencers_preprocessed_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mw_dataset_no_dup_no_troll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
