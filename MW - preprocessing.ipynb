{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import datetime as datetime \n",
    "import pickle \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll = pd.read_csv('SG_twitter_complete_dataset.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mw_dataset_no_dup_no_troll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>valence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_joining_date</th>\n",
       "      <th>user_status_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224742687137419264</td>\n",
       "      <td>2020-02-05 01:13:05</td>\n",
       "      <td>Coronavirus outbreak: Singapore to provide S$1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.517</td>\n",
       "      <td>3099154459</td>\n",
       "      <td>2015-03-20 15:42:35</td>\n",
       "      <td>9415</td>\n",
       "      <td>150</td>\n",
       "      <td>103</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224741485859557378</td>\n",
       "      <td>2020-02-05 01:08:19</td>\n",
       "      <td>Coronavirus: Royal Caribbean warns of more cru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1200474236</td>\n",
       "      <td>2013-02-20 18:48:39</td>\n",
       "      <td>30905</td>\n",
       "      <td>22711</td>\n",
       "      <td>72</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224739548690694144</td>\n",
       "      <td>2020-02-05 01:00:37</td>\n",
       "      <td>The Wuhan Coronavirus Poses Three Tests for Gl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WuhanCoronavirus</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1117748674090504195</td>\n",
       "      <td>2019-04-15 19:17:05</td>\n",
       "      <td>1776</td>\n",
       "      <td>90</td>\n",
       "      <td>638</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224738837198278656</td>\n",
       "      <td>2020-02-05 00:57:47</td>\n",
       "      <td>@asadowaisi Pakistan is not rescuing their peo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.428</td>\n",
       "      <td>110612755</td>\n",
       "      <td>2010-02-02 12:39:06</td>\n",
       "      <td>4891</td>\n",
       "      <td>280</td>\n",
       "      <td>346</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224738184614907904</td>\n",
       "      <td>2020-02-05 00:55:12</td>\n",
       "      <td>The world will pay a growth price for the Wuha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1117748674090504195</td>\n",
       "      <td>2019-04-15 19:17:05</td>\n",
       "      <td>1776</td>\n",
       "      <td>90</td>\n",
       "      <td>638</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID keywords             tweet_ID      tweet_timestamp  \\\n",
       "0   1    wuhan  1224742687137419264  2020-02-05 01:13:05   \n",
       "1   2    wuhan  1224741485859557378  2020-02-05 01:08:19   \n",
       "2   3    wuhan  1224739548690694144  2020-02-05 01:00:37   \n",
       "3   4    wuhan  1224738837198278656  2020-02-05 00:57:47   \n",
       "4   5    wuhan  1224738184614907904  2020-02-05 00:55:12   \n",
       "\n",
       "                                               Tweet  retweet_count  \\\n",
       "0  Coronavirus outbreak: Singapore to provide S$1...              0   \n",
       "1  Coronavirus: Royal Caribbean warns of more cru...              0   \n",
       "2  The Wuhan Coronavirus Poses Three Tests for Gl...              0   \n",
       "3  @asadowaisi Pakistan is not rescuing their peo...              0   \n",
       "4  The world will pay a growth price for the Wuha...              0   \n",
       "\n",
       "   favourite_count          HashTags  anger   fear  sadness    joy  valence  \\\n",
       "0                0               NaN  0.342  0.508    0.394  0.290    0.517   \n",
       "1                0               NaN  0.452  0.636    0.467  0.238    0.400   \n",
       "2                0  WuhanCoronavirus  0.334  0.460    0.349  0.331    0.480   \n",
       "3                0               NaN  0.405  0.422    0.432  0.230    0.428   \n",
       "4                1               NaN  0.335  0.412    0.337  0.352    0.522   \n",
       "\n",
       "               user_id    user_joining_date  user_status_count  \\\n",
       "0           3099154459  2015-03-20 15:42:35               9415   \n",
       "1           1200474236  2013-02-20 18:48:39              30905   \n",
       "2  1117748674090504195  2019-04-15 19:17:05               1776   \n",
       "3            110612755  2010-02-02 12:39:06               4891   \n",
       "4  1117748674090504195  2019-04-15 19:17:05               1776   \n",
       "\n",
       "   user_followers  user_friends   location  \n",
       "0             150           103  Singapore  \n",
       "1           22711            72  Singapore  \n",
       "2              90           638  Singapore  \n",
       "3             280           346  Singapore  \n",
       "4              90           638  Singapore  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'keywords', 'tweet_ID', 'tweet_timestamp', 'Tweet',\n",
       "       'retweet_count', 'favourite_count', 'HashTags', 'anger', 'fear',\n",
       "       'sadness', 'joy', 'valence', 'user_id', 'user_joining_date',\n",
       "       'user_status_count', 'user_followers', 'user_friends', 'location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll['Tweet'] = mw_dataset_no_dup_no_troll['Tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "def clean_text_1(headline):\n",
    "    headline = headline.lower()\n",
    "    headline = re.sub('\\[.,*?\\]','',headline)\n",
    "    headline = re.sub('[0-9]','',headline)\n",
    "    headline = re.sub('[%s]' % re.escape(string.punctuation), '', headline)\n",
    "    headline = re.sub('[‘’“”…–]', '', headline)\n",
    "    headline = re.sub('\\w*\\d\\n\\w*', '', headline)\n",
    "    return headline\n",
    "\n",
    "#def replace_contractions(text):\n",
    "    #\"\"\"Replace contractions in string of text\"\"\"\n",
    "    #return contractions.fix(text)\n",
    "\n",
    "def remove_mentions(sample):\n",
    "    \"\"\"Remove mentions from a sample string\"\"\"\n",
    "    return re.sub(r\"@\\S+\", \"\", str(sample))\n",
    "    \n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", str(sample))\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', str(word))\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def normalize(words):\n",
    "    #words = replace_numbers(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    return words\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample = remove_URL(sample)\n",
    "    sample= remove_mentions(sample)\n",
    "    #sample = replace_contractions(sample)\n",
    "    # Tokenize\n",
    "    words = nltk.word_tokenize(sample)\n",
    "\n",
    "    # Normalize\n",
    "    return normalize(words)\n",
    "\n",
    "\n",
    "round_1 = lambda x: preprocess(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll['processed_content'] = mw_dataset_no_dup_no_troll['Tweet'].apply(round_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll['processed_content']=mw_dataset_no_dup_no_troll['processed_content'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    coronavirus outbreak singapore to provide s 1 ...\n",
       "1    coronavirus royal caribbean warns of more crui...\n",
       "2    the wuhan coronavirus poses three tests for gl...\n",
       "3    pakistan is not rescuing their people from wuh...\n",
       "4    the world will pay a growth price for the wuha...\n",
       "Name: processed_content, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll['processed_content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>valence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_joining_date</th>\n",
       "      <th>user_status_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>location</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224742687137419264</td>\n",
       "      <td>2020-02-05 01:13:05</td>\n",
       "      <td>Coronavirus outbreak: Singapore to provide S$1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.517</td>\n",
       "      <td>3099154459</td>\n",
       "      <td>2015-03-20 15:42:35</td>\n",
       "      <td>9415</td>\n",
       "      <td>150</td>\n",
       "      <td>103</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>coronavirus outbreak singapore to provide s 1 ...</td>\n",
       "      <td>coronavirus outbreak singapor to provid s 1 mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224741485859557378</td>\n",
       "      <td>2020-02-05 01:08:19</td>\n",
       "      <td>Coronavirus: Royal Caribbean warns of more cru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1200474236</td>\n",
       "      <td>2013-02-20 18:48:39</td>\n",
       "      <td>30905</td>\n",
       "      <td>22711</td>\n",
       "      <td>72</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>coronavirus royal caribbean warns of more crui...</td>\n",
       "      <td>coronavirus royal caribbean warn of more cruis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224739548690694144</td>\n",
       "      <td>2020-02-05 01:00:37</td>\n",
       "      <td>The Wuhan Coronavirus Poses Three Tests for Gl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WuhanCoronavirus</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1117748674090504195</td>\n",
       "      <td>2019-04-15 19:17:05</td>\n",
       "      <td>1776</td>\n",
       "      <td>90</td>\n",
       "      <td>638</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>the wuhan coronavirus poses three tests for gl...</td>\n",
       "      <td>the wuhan coronavirus pose three test for glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224738837198278656</td>\n",
       "      <td>2020-02-05 00:57:47</td>\n",
       "      <td>@asadowaisi Pakistan is not rescuing their peo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.428</td>\n",
       "      <td>110612755</td>\n",
       "      <td>2010-02-02 12:39:06</td>\n",
       "      <td>4891</td>\n",
       "      <td>280</td>\n",
       "      <td>346</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>pakistan is not rescuing their people from wuh...</td>\n",
       "      <td>sadowaisi pakistan is not rescu their peopl fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224738184614907904</td>\n",
       "      <td>2020-02-05 00:55:12</td>\n",
       "      <td>The world will pay a growth price for the Wuha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1117748674090504195</td>\n",
       "      <td>2019-04-15 19:17:05</td>\n",
       "      <td>1776</td>\n",
       "      <td>90</td>\n",
       "      <td>638</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>the world will pay a growth price for the wuha...</td>\n",
       "      <td>the world will pay a growth price for the wuha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID keywords             tweet_ID      tweet_timestamp  \\\n",
       "0   1    wuhan  1224742687137419264  2020-02-05 01:13:05   \n",
       "1   2    wuhan  1224741485859557378  2020-02-05 01:08:19   \n",
       "2   3    wuhan  1224739548690694144  2020-02-05 01:00:37   \n",
       "3   4    wuhan  1224738837198278656  2020-02-05 00:57:47   \n",
       "4   5    wuhan  1224738184614907904  2020-02-05 00:55:12   \n",
       "\n",
       "                                               Tweet  retweet_count  \\\n",
       "0  Coronavirus outbreak: Singapore to provide S$1...              0   \n",
       "1  Coronavirus: Royal Caribbean warns of more cru...              0   \n",
       "2  The Wuhan Coronavirus Poses Three Tests for Gl...              0   \n",
       "3  @asadowaisi Pakistan is not rescuing their peo...              0   \n",
       "4  The world will pay a growth price for the Wuha...              0   \n",
       "\n",
       "   favourite_count          HashTags  anger   fear  sadness    joy  valence  \\\n",
       "0                0               NaN  0.342  0.508    0.394  0.290    0.517   \n",
       "1                0               NaN  0.452  0.636    0.467  0.238    0.400   \n",
       "2                0  WuhanCoronavirus  0.334  0.460    0.349  0.331    0.480   \n",
       "3                0               NaN  0.405  0.422    0.432  0.230    0.428   \n",
       "4                1               NaN  0.335  0.412    0.337  0.352    0.522   \n",
       "\n",
       "               user_id    user_joining_date  user_status_count  \\\n",
       "0           3099154459  2015-03-20 15:42:35               9415   \n",
       "1           1200474236  2013-02-20 18:48:39              30905   \n",
       "2  1117748674090504195  2019-04-15 19:17:05               1776   \n",
       "3            110612755  2010-02-02 12:39:06               4891   \n",
       "4  1117748674090504195  2019-04-15 19:17:05               1776   \n",
       "\n",
       "   user_followers  user_friends   location  \\\n",
       "0             150           103  Singapore   \n",
       "1           22711            72  Singapore   \n",
       "2              90           638  Singapore   \n",
       "3             280           346  Singapore   \n",
       "4              90           638  Singapore   \n",
       "\n",
       "                                   processed_content  \\\n",
       "0  coronavirus outbreak singapore to provide s 1 ...   \n",
       "1  coronavirus royal caribbean warns of more crui...   \n",
       "2  the wuhan coronavirus poses three tests for gl...   \n",
       "3  pakistan is not rescuing their people from wuh...   \n",
       "4  the world will pay a growth price for the wuha...   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0  coronavirus outbreak singapor to provid s 1 mi...  \n",
       "1  coronavirus royal caribbean warn of more cruis...  \n",
       "2  the wuhan coronavirus pose three test for glob...  \n",
       "3  sadowaisi pakistan is not rescu their peopl fr...  \n",
       "4  the world will pay a growth price for the wuha...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mw_dataset_no_dup_no_troll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#fb_clean['processed_content'] = fb_clean['processed_content'].astype('str').apply(lambda x: filter(None,x.split(\" \")))\n",
    "#fb_clean['processed_content'] = fb_clean['processed_content'].apply(lambda x : [wordnet_lemmatizer.lemmatize(y) for y in x])\n",
    "#fb_clean['processed_content']=fb_clean['processed_content'].apply(lambda x : \" \".join(x))\n",
    "\n",
    "mw_dataset_no_dup_no_troll['lemmatized_content'] = mw_dataset_no_dup_no_troll['processed_content'].astype('str').apply(lambda x: filter(None,x.split(\" \")))\n",
    "#df['processed_content'] = df['processed_content'].apply(lambda x : [wordnet_lemmatizer.lemmatize(y) for y in x])\n",
    "mw_dataset_no_dup_no_troll['lemmatized_content'] = mw_dataset_no_dup_no_troll['lemmatized_content'].apply(lambda x : [stemmer.stem(y) for y in x])\n",
    "mw_dataset_no_dup_no_troll['lemmatized_content'] = mw_dataset_no_dup_no_troll['lemmatized_content'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>valence</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_joining_date</th>\n",
       "      <th>user_status_count</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>location</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>lemmatized_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224742687137419264</td>\n",
       "      <td>2020-02-05 01:13:05</td>\n",
       "      <td>Coronavirus outbreak: Singapore to provide S$1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.517</td>\n",
       "      <td>3099154459</td>\n",
       "      <td>2015-03-20 15:42:35</td>\n",
       "      <td>9415</td>\n",
       "      <td>150</td>\n",
       "      <td>103</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>coronavirus outbreak singapore to provide s 1 ...</td>\n",
       "      <td>coronavirus outbreak singapor to provid s 1 mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224741485859557378</td>\n",
       "      <td>2020-02-05 01:08:19</td>\n",
       "      <td>Coronavirus: Royal Caribbean warns of more cru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1200474236</td>\n",
       "      <td>2013-02-20 18:48:39</td>\n",
       "      <td>30905</td>\n",
       "      <td>22711</td>\n",
       "      <td>72</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>coronavirus royal caribbean warns of more crui...</td>\n",
       "      <td>coronavirus royal caribbean warn of more cruis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224739548690694144</td>\n",
       "      <td>2020-02-05 01:00:37</td>\n",
       "      <td>The Wuhan Coronavirus Poses Three Tests for Gl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WuhanCoronavirus</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.480</td>\n",
       "      <td>1117748674090504195</td>\n",
       "      <td>2019-04-15 19:17:05</td>\n",
       "      <td>1776</td>\n",
       "      <td>90</td>\n",
       "      <td>638</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>the wuhan coronavirus poses three tests for gl...</td>\n",
       "      <td>the wuhan coronavirus pose three test for glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224738837198278656</td>\n",
       "      <td>2020-02-05 00:57:47</td>\n",
       "      <td>@asadowaisi Pakistan is not rescuing their peo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.428</td>\n",
       "      <td>110612755</td>\n",
       "      <td>2010-02-02 12:39:06</td>\n",
       "      <td>4891</td>\n",
       "      <td>280</td>\n",
       "      <td>346</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>pakistan is not rescuing their people from wuh...</td>\n",
       "      <td>pakistan is not rescu their peopl from wuhan i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wuhan</td>\n",
       "      <td>1224738184614907904</td>\n",
       "      <td>2020-02-05 00:55:12</td>\n",
       "      <td>The world will pay a growth price for the Wuha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1117748674090504195</td>\n",
       "      <td>2019-04-15 19:17:05</td>\n",
       "      <td>1776</td>\n",
       "      <td>90</td>\n",
       "      <td>638</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>the world will pay a growth price for the wuha...</td>\n",
       "      <td>the world will pay a growth price for the wuha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID keywords             tweet_ID      tweet_timestamp  \\\n",
       "0   1    wuhan  1224742687137419264  2020-02-05 01:13:05   \n",
       "1   2    wuhan  1224741485859557378  2020-02-05 01:08:19   \n",
       "2   3    wuhan  1224739548690694144  2020-02-05 01:00:37   \n",
       "3   4    wuhan  1224738837198278656  2020-02-05 00:57:47   \n",
       "4   5    wuhan  1224738184614907904  2020-02-05 00:55:12   \n",
       "\n",
       "                                               Tweet  retweet_count  \\\n",
       "0  Coronavirus outbreak: Singapore to provide S$1...              0   \n",
       "1  Coronavirus: Royal Caribbean warns of more cru...              0   \n",
       "2  The Wuhan Coronavirus Poses Three Tests for Gl...              0   \n",
       "3  @asadowaisi Pakistan is not rescuing their peo...              0   \n",
       "4  The world will pay a growth price for the Wuha...              0   \n",
       "\n",
       "   favourite_count          HashTags  anger   fear  sadness    joy  valence  \\\n",
       "0                0               NaN  0.342  0.508    0.394  0.290    0.517   \n",
       "1                0               NaN  0.452  0.636    0.467  0.238    0.400   \n",
       "2                0  WuhanCoronavirus  0.334  0.460    0.349  0.331    0.480   \n",
       "3                0               NaN  0.405  0.422    0.432  0.230    0.428   \n",
       "4                1               NaN  0.335  0.412    0.337  0.352    0.522   \n",
       "\n",
       "               user_id    user_joining_date  user_status_count  \\\n",
       "0           3099154459  2015-03-20 15:42:35               9415   \n",
       "1           1200474236  2013-02-20 18:48:39              30905   \n",
       "2  1117748674090504195  2019-04-15 19:17:05               1776   \n",
       "3            110612755  2010-02-02 12:39:06               4891   \n",
       "4  1117748674090504195  2019-04-15 19:17:05               1776   \n",
       "\n",
       "   user_followers  user_friends   location  \\\n",
       "0             150           103  Singapore   \n",
       "1           22711            72  Singapore   \n",
       "2              90           638  Singapore   \n",
       "3             280           346  Singapore   \n",
       "4              90           638  Singapore   \n",
       "\n",
       "                                   processed_content  \\\n",
       "0  coronavirus outbreak singapore to provide s 1 ...   \n",
       "1  coronavirus royal caribbean warns of more crui...   \n",
       "2  the wuhan coronavirus poses three tests for gl...   \n",
       "3  pakistan is not rescuing their people from wuh...   \n",
       "4  the world will pay a growth price for the wuha...   \n",
       "\n",
       "                                  lemmatized_content  \n",
       "0  coronavirus outbreak singapor to provid s 1 mi...  \n",
       "1  coronavirus royal caribbean warn of more cruis...  \n",
       "2  the wuhan coronavirus pose three test for glob...  \n",
       "3  pakistan is not rescu their peopl from wuhan i...  \n",
       "4  the world will pay a growth price for the wuha...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_dataset_no_dup_no_troll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_dataset_no_dup_no_troll.to_csv('SG_twitter_preprocessed_V2_26AUG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674662"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mw_dataset_no_dup_no_troll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
